{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reddit Scraper Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XjFHk7WzY5W",
        "colab_type": "text"
      },
      "source": [
        "###Reddit Comment Scraper\n",
        "\n",
        "Scroll down to main function to substitute parameters\n",
        "\n",
        "Returns eleven .csv files. One for each of the 10 hottest posts' comments of the subreddit of your choosing and one for the ten posts.\n",
        "\n",
        "1. Posts and their general information\n",
        "2. All the comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGbNMCeSpZsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "'''\n",
        "@author: osamah Abdelhaq\n",
        "'''\n",
        "\n",
        "#Requires PRAW\n",
        "!pip install praw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCfjiqsm9QRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import praw\n",
        "from praw.models import MoreComments"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1dBEUKa-3nN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#==================Functions===================\n",
        "\n",
        "class RedditBot():\n",
        "\n",
        "  def __init__(self,client_id,client_secret,subreddit,user_agent):\n",
        "    self.client_id = client_id\n",
        "    self.client_secret = client_secret\n",
        "    self.subreddit = subreddit\n",
        "    self.user_agent = user_agent\n",
        "\n",
        "  #API Call\n",
        "  def API(self,subreddit,client_id,client_secret,user_agent):\n",
        "    reddit = praw.Reddit(client_id=self.client_id,\\\n",
        "                        client_secret=self.client_secret,\\\n",
        "                        user_agent=self.user_agent)\n",
        "    if (reddit != False):\n",
        "      print(\"API token successful\")\n",
        "    else:\n",
        "      print(\"API token unsuccessful\")\n",
        "    return reddit\n",
        "\n",
        "  #get 10 hottest posts from the subreddit\n",
        "  def hot(self,reddit,subreddit):\n",
        "    '''\n",
        "    Method gets the top ten posts from the subreddit and returns a csv\n",
        "    '''\n",
        "    hot_posts = reddit.subreddit(subreddit).hot(limit=10)\n",
        "\n",
        "    #empty array for storage\n",
        "    posts = []\n",
        "\n",
        "    ss_subreddit = reddit.subreddit(subreddit)\n",
        "\n",
        "    #print Subreddit Description\n",
        "    print(\"Subreddit Description: \", ss_subreddit.description)\n",
        "\n",
        "    print(\"***Top 10 Subreddit Thread Titles:***\")\n",
        "\n",
        "    #store elements of subreddit\n",
        "    for post in ss_subreddit.hot(limit=10):\n",
        "      posts.append([post.title, post.score, post.id, post.subreddit,\\\n",
        "                    post.url, post.num_comments, post.selftext, post.created])\n",
        "\n",
        "    #create Pandas dataframe for easy access\n",
        "    posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url',\\\n",
        "                                        'num_comments', 'body', 'created'])\n",
        "\n",
        "    #*****Path to Store CSV*****\n",
        "    posts.to_csv(r'C:\\Users\\osama\\Desktop\\StimulusCheckPosts.csv')\n",
        "\n",
        "    print(posts[0:10])\n",
        "\n",
        "    return posts\n",
        "\n",
        "  #Retrieve Comments\n",
        "  def comments(self,posts,reddit):\n",
        "\n",
        "    '''\n",
        "    Method scrapes all first level comments, then all second level comments, etc\n",
        "    Returns 10 csv files, one for each of the top ten subreddit posts\n",
        "    '''\n",
        "\n",
        "    for index, id in enumerate(posts.id):\n",
        "      all_comments = []\n",
        "      all_comments.clear() #just to be sure\n",
        "      sub = reddit.submission(id=id)\n",
        "      sub.comments.replace_more(limit=0)\n",
        "\n",
        "      for comment in sub.comments.list():\n",
        "        all_comments.append(comment.body)\n",
        "\n",
        "      all_comments = pd.DataFrame(all_comments,columns=['Comments'])\n",
        "\n",
        "      #*****Path to Store CSV*****\n",
        "      all_comments.to_csv(rf'C:\\Users\\osama\\Desktop\\{index}.csv')\n",
        "\n",
        "    return\n",
        "#===================End Helper Functions===================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fud1GCbjysfu",
        "colab_type": "code",
        "outputId": "97628b39-c467-42fe-95ae-faa906dec553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#====================Main=======================\n",
        "def main():\n",
        "#===================Variables===================\n",
        "  subreddit = 'StimulusCheck' #enter desired subreddit\n",
        "  client_id = 'EnterClientID'\n",
        "  client_secret = 'EnterClientSecretID'\n",
        "#====================End Variables==================\n",
        "\n",
        "  user_agent = 'my_user_agent'\n",
        "\n",
        "  #initiate instance\n",
        "  r = RedditBot(client_id,client_secret,subreddit,user_agent)\n",
        "\n",
        "  #login with API\n",
        "  navigation = r.API(client_id,client_secret,subreddit,user_agent)\n",
        "\n",
        "  #use API to collect 10 hottest posts\n",
        "  posts = r.hot(navigation,subreddit)\n",
        "\n",
        "  #use API to collect all comments\n",
        "  comments = r.comments(posts,navigation)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "API token successful\n",
            "Subreddit Description:  Everything about the government’s coronavirus stimulus check\n",
            "***Top 10 Subreddit Thread Titles:***\n",
            "                                               title  ...       created\n",
            "0      Daily Stimulus Check Support Group MEGATHREAD  ...  1.588161e+09\n",
            "1                      Stimulus check 2.0 discussion  ...  1.590996e+09\n",
            "2  \"Your address was too long so we just cut it i...  ...  1.591658e+09\n",
            "3    PSNA mystery solved- useful info for immigrants  ...  1.591674e+09\n",
            "4           Got an update finally from a live person  ...  1.591677e+09\n",
            "5                                   Stimulus Is Here  ...  1.591642e+09\n",
            "6  New IRS site - https://irs.gov/coronavirus/whe...  ...  1.591685e+09\n",
            "7      Stuck on “mailed” status (partially resolved)  ...  1.591672e+09\n",
            "8                            Information not present  ...  1.591668e+09\n",
            "9  PSNA when claimed as a dependent in 2018 but n...  ...  1.591678e+09\n",
            "\n",
            "[10 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
